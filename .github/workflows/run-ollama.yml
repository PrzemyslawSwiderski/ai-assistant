name: Run Ollama Docker Container

on:
  workflow_dispatch:  # Allows manual triggering of the workflow
    inputs:
      model:
        description: 'Model'
        required: true
        default: 'deepseek-r1'
        type: string
      query:
        description: 'Query'
        required: true
        default: '"What is the most populous city in the middle of Poland?"'
        type: string

env:
  IMAGE_TAG: "ghcr.io/przemyslawswiderski/ai-assistant:latest"

jobs:
  run-ollama:
    runs-on: ubuntu-latest  # Use the latest Ubuntu runner

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4.2.2  # Check out the repository code

      - name: Set up Docker
        id: docker
        uses: docker/setup-buildx-action@v3.9.0  # Set up Docker Build

      - name: Pull Ollama Docker image
        run: docker pull ${{ env.IMAGE_TAG }}  # Replace with the correct image name

      - name: Cache Ollama Models
        id: cache-ollama
        uses: actions/cache@v4
        with:
          path: ollama-data/models
          key: ollama_cache_${{ github.event.inputs.model }}

      - name: Run Ollama Docker container
        run: |
          docker run -d \
            --name ollama-container \
            -v ./ollama-data:/root/.ollama \
            ${{ env.IMAGE_TAG }}

      - name: Wait for Ollama to start
        run: sleep 5  # Give the container some time to initialize

      - name: Pull AI model
        if: steps.cache-ollama.outputs.cache-hit != 'true'
        run: |
          docker exec ollama-container \
            ollama pull ${{ github.event.inputs.model }}

      - name: Execute Ollama query
        run: |
          docker exec ollama-container \
            ollama run ${{ github.event.inputs.model }} ${{ github.event.inputs.query }}

      - name: Verify output
        run: |
          echo "Query executed successfully!"
